{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d7066b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df=pd.read_excel('input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c3ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a4b47",
   "metadata": {},
   "source": [
    "#### Using Beautiful Soup to scrape article text from the article link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "217760f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\n",
      "38\n",
      "https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\n",
      "39\n",
      "https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8588722f83b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,j in df.iterrows():\n",
    "    filename=str(j['URL_ID'])+\".txt\"\n",
    "    print(j['URL_ID'])\n",
    "    print(j['URL'])\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "    page=requests.get(j['URL'],headers=headers,)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')\n",
    "    pattern=\"<[^\\>]*>\"\n",
    "    title = re.sub(pattern,\"\",str(soup.find('title') ))\n",
    "    content=re.sub(pattern,\"\",str(soup.find_all('p')))\n",
    "    with open (filename, 'w', newline='',encoding='utf-8') as f:\n",
    "        f.write(title)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(content)\n",
    "        f.write(\"\\n\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8ef2e",
   "metadata": {},
   "source": [
    "#### Reading stop word files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb31057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "auditor= open(\"StopWords\\\\StopWords_Auditor.txt\",'r').read()\n",
    "currency=open(\"StopWords\\\\StopWords_Currencies.txt\",'r').read()\n",
    "datesandnumbers=open(\"StopWords\\\\StopWords_DatesandNumbers.txt\",'r').read()\n",
    "generic=open(\"StopWords\\\\StopWords_Generic.txt\",'r').read()\n",
    "genericlong=open(\"StopWords\\\\StopWords_GenericLong.txt\",'r').read()\n",
    "geographic=open(\"StopWords\\\\StopWords_Geographic.txt\",'r').read()\n",
    "names=open(\"StopWords\\\\StopWords_Names.txt\",'r').read()\n",
    "\n",
    "\n",
    "STOP_WORDS=auditor+currency+datesandnumbers+generic+genericlong+geographic+names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9400d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNST\n",
      "YOUNG\n",
      "DELOITTE\n",
      "TOUCHE\n",
      "KPMG\n",
      "PRICEWATERHOUSECOOPERS\n",
      "PRICEWATERHOUSE\n",
      "COOPERS\n",
      "AFGHANI  | Afghanist\n"
     ]
    }
   ],
   "source": [
    "print(STOP_WORDS[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6033e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dcabb9",
   "metadata": {},
   "source": [
    "#### Reading article text from the scaped text files into the output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9880099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is FE7D-6C16\n",
      "\n",
      " Directory of C:\\Users\\tomar\\Downloads\\Case Studies\\20211030 Test Assignment-20221116T043615Z-001\\20211030 Test Assignment Solution\n",
      "\n",
      "21-11-2022  03:47 PM    <DIR>          .\n",
      "21-11-2022  03:47 PM    <DIR>          ..\n",
      "21-11-2022  03:47 PM    <DIR>          .ipynb_checkpoints\n",
      "16-11-2022  10:07 AM            14,625 Input.xlsx\n",
      "16-11-2022  10:07 AM    <DIR>          MasterDictionary\n",
      "16-11-2022  10:07 AM            11,952 Objective.docx\n",
      "16-11-2022  10:07 AM            15,877 Output Data Structure.xlsx\n",
      "21-11-2022  03:36 PM    <DIR>          Scraped Text\n",
      "21-11-2022  03:37 PM           120,298 SentimentalAnalysisAssignmentSolution (Gaurav Tomar).ipynb\n",
      "16-11-2022  10:07 AM    <DIR>          StopWords\n",
      "16-11-2022  10:07 AM            14,551 Text Analysis.docx\n",
      "               5 File(s)        177,303 bytes\n",
      "               6 Dir(s)   3,278,475,264 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5a6aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df=df[['URL_ID', 'URL']].copy()\n",
    "text_list = list()\n",
    "\n",
    "for index,row in output_df.iterrows():\n",
    "    article_text=(open('Scraped Text\\\\{}.txt'.format(str(row[\"URL_ID\"])), encoding='utf-8').read())\n",
    "    text_list.append(article_text)\n",
    "output_df['text']=text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16779ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10ecaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.text.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa9a6b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Will AI Replace Us or Work With Us? - Blackcof...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "\n",
       "                                                text  \n",
       "0  AI in healthcare to Improve Patient Outcomes -...  \n",
       "1  What if the Creation is Taking Over the Creato...  \n",
       "2  What Jobs Will Robots Take From Humans in The ...  \n",
       "3  Will Machine Replace The Human in the Future o...  \n",
       "4  Will AI Replace Us or Work With Us? - Blackcof...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e07e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>Blockchain for Payments - Blackcoffer Insights...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>The future of Investing - Blackcoffer Insights...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>Big Data Analytics in Healthcare - Blackcoffer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>Business Analytics In The Healthcare Industry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "                                                  text  \n",
       "109  Blockchain for Payments - Blackcoffer Insights...  \n",
       "110  The future of Investing - Blackcoffer Insights...  \n",
       "111  Big Data Analytics in Healthcare - Blackcoffer...  \n",
       "112  Business Analytics In The Healthcare Industry ...  \n",
       "113  Challenges and Opportunities of Big Data in He...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd4aec",
   "metadata": {},
   "source": [
    "#### Removing the stopwords (given) from the article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0a92cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list=list(STOP_WORDS.split(\"\\n\"))\n",
    "from nltk import word_tokenize\n",
    "article_word_list = list()\n",
    "for article_text in output_df['text']:\n",
    "    token=word_tokenize(article_text)\n",
    "    article_words = [word for word in token if word not in stopwords_list]\n",
    "    article_word_list.append(article_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17f33232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['healthcare', 'Improve', 'Patient', 'Outcomes', '-', 'Blackcoffer', 'Insights', '[', 'Introduction', ',', '“', 'If', 'kills', '10', 'million', 'people', 'decades', ',', 'a', 'highly', 'infectious', 'virus', 'a', 'war', '.', 'Not', 'missiles', 'microbes.', '”', 'Bill', 'Gates', '’', 'remarks', 'a', 'conference', '2014', ',', 'world', 'avoided', 'Ebola', 'outbreak', '.', 'When', ',', 'unprecedented', ',', 'invisible', 'virus', 'hit', ',', 'met', 'overwhelmed', 'unprepared', 'healthcare', 'system', 'oblivious', 'population', '.', 'This', 'public', 'health', 'emergency', 'demonstrated', 'lack', 'scientific', 'consideration', 'underlined', 'alarming', 'robust', 'innovations', 'health', 'medical', 'facilities', '.', 'For', 'past', 'years', ',', 'artificial', 'intelligence', 'proven', 'tangible', 'potential', 'healthcare', 'sectors', ',', 'clinical', 'practices', ',', 'translational', 'medical', 'biomedical', 'research.', ',', 'After', 'case', 'detected', 'China', 'December', '31st', '2019', ',', 'program', 'developed', 'BlueDot', 'alerted', 'world', 'pandemic', '.', 'It', 'quick', 'realise', '’', 'ability', 'analyse', 'large', 'chunks', 'data', 'detecting', 'patterns', 'identifying', 'tracking', 'carriers', 'virus.', ',', 'Many', 'tracing', 'apps', 'tabs', 'people', 'infected', 'prevent', 'risk', 'cross-infection', 'algorithms', 'track', 'patterns', 'extract', 'features', 'classify', 'categorise', 'them.', ',', 'So', '?', ',', 'IBM', 'Watson', ',', 'a', 'sophisticated', 'works', 'cloud', 'computing', 'natural', 'language', 'processing', ',', 'prominently', 'contributed', 'healthcare', 'sector', 'a', 'global', 'level', '.', 'Being', 'a', 'conversational', ',', '2013', ',', 'Watson', 'helped', 'recommending', 'treatments', 'patients', 'suffering', 'cancer', 'ensure', 'treatment', 'optimum', 'costs.', ',', 'Researchers', 'Google', 'Inc.', 'showed', 'system', 'trained', 'thousands', 'images', 'achieve', 'physician-level', 'sensitivity.', ',', 'By', 'identifying', 'molecular', 'patterns', 'disease', 'status', 'subtypes', ',', 'gene', 'expression', ',', 'protein', 'abundance', 'levels', ',', 'machine', 'learning', 'methods', 'detect', 'fatal', 'diseases', 'cancer', 'early', 'stage', '.', 'Machine', 'Learning', '(', 'ML', ')', 'techniques', 'focus', 'analyzing', 'structured', 'data', ',', 'clustering', 'patients', '’', 'traits', 'infer', 'probability', 'disease', 'outcomes', '.', 'Since', 'patient', 'traits', 'include', 'masses', 'data', 'relating', 'age', ',', 'gender', ',', 'disease', 'history', ',', 'disease-specific', 'data', 'diagnostic', 'imaging', 'gene', 'expressions', ',', ',', 'ML', 'extract', 'features', 'data', 'inputs', 'constructing', 'data', 'analytical', 'algorithms.', ',', 'ML', 'algorithms', 'supervised', 'unsupervised', '.', 'Unsupervised', 'learning', 'helps', 'extracting', 'features', 'clustering', 'similar', 'features', 'leads', 'early', 'detection', 'diseases', '.', 'Clustering', 'principal', 'component', 'analysis', 'enable', 'grouping', 'clustering', 'similar', 'traits', 'maximize', 'minimize', 'similarity', 'patients', 'clusters', '.', 'Since', 'patient', 'traits', 'recorded', 'multiple', 'dimensions', ',', 'genes', ',', 'principal', 'component', 'analysis', '(', 'PCA', ')', 'creates', 'apparatus', 'reduce', 'dimensions', 'humans', 'alone.', ',', 'Supervised', 'learning', 'considers', 'outcomes', 'subjects', 'traits', ',', 'correlates', 'inputs', 'outputs', 'predict', 'probability', 'a', 'clinical', 'event', ',', 'expected', 'a', 'disease', 'level', 'expected', 'survival', 'time', ',', 'risk', 'Down', '’', 'syndrome.', ',', 'Biomarker', 'panels', 'detect', 'ovarian', 'cancer', ',', 'outperformed', 'conventional', 'statistical', 'methods', 'due', 'machine', 'learning', '.', 'In', 'addition', ',', 'EHRs', 'Bayesian', 'networks', ',', 'a', 'part', 'supervised', 'machine', 'learning', 'algorithms', ',', 'predict', 'clinical', 'outcomes', 'mortality', 'respectively.', ',', 'Unstructured', 'data', 'clinical', 'notes', 'texts', 'converted', 'machine-readable', 'structured', 'data', 'natural', 'language', 'processing', '(', 'NLP', ')', '.', 'NLP', 'works', 'components', ':', 'text', 'processing', 'classification', '.', 'Text', 'processing', 'helps', 'identifying', 'a', 'series', 'disease-relevant', 'keywords', 'clinical', 'notes', 'classification', 'categorized', 'normal', 'abnormal', 'cases', '.', 'Chest', 'screening', 'ML', 'NLP', 'helped', 'find', 'abnormalities', 'lungs', 'provide', 'treatment', 'covid', 'patients', '.', 'Healthcare', 'organizations', 'NLP-based', 'chatbots', 'increase', 'interactions', 'patients', ',', 'keeping', 'mental', 'health', 'wellness', 'check.', ',', 'Deep', 'learning', 'a', 'modern', 'extension', 'classical', 'neural', 'network', 'techniques', 'helps', 'explore', 'complex', 'non-linear', 'patterns', 'data', ',', 'algorithms', 'convolution', 'neural', 'network', ',', 'recurrent', 'neural', 'network', ',', 'deep', 'belief', 'network', ',', 'deep', 'neural', 'network', 'enables', 'accurate', 'clinical', 'prediction', '.', 'When', 'genome', 'interpretation', ',', 'deep', 'neural', 'networks', 'surpass', 'conventional', 'methods', 'logistics', 'regression', 'support', 'vector', 'machines.', ',', 'Sepsis', 'Watch', 'system', 'trained', 'deep', 'learning', 'algorithms', 'holds', 'capability', 'analyze', '32', 'million', 'data', 'points', 'create', 'a', 'patient', '’', 'risk', 'score', 'identify', 'early', 'stages', 'sepsis.', ',', 'Another', 'method', 'Learning-based', 'Optimization', 'Under', 'Sampling', 'Pattern', '(', 'LOUPE', ')', 'based', 'integrating', 'full', 'resolution', 'MRI', 'scans', 'convolutional', 'neural', 'network', 'algorithm', ',', 'helps', 'creating', 'accurate', 'reconstructions.', ',', 'Robotic', 'surgery', 'widely', 'considered', 'delicate', 'surgeries', 'gynaecology', 'prostate', 'surgery', '.', 'Even', 'striking', 'balance', 'human', 'decisions', 'precision', ',', 'robotic', 'surgery', 'reduces', 'surgeon', 'efficiency', 'manually', 'operated', 'a', 'console', '.', 'Thus', ',', 'autonomous', 'robotic', 'surgery', 'rise', 'inventions', 'robotic', 'silicon', 'fingers', 'mimic', 'sense', 'touch', 'surgeons', 'identify', 'organs', ',', 'cut', 'tissues', ',', 'etc.', ',', 'robotic', 'catheters', 'navigate', 'touching', 'blood', ',', 'tissue', ',', 'valve.', ',', 'Researchers', 'Children', '’', 'National', 'Hospital', ',', 'Washington', 'developed', 'called', 'Smart', 'Tissue', 'Autonomous', 'Robot', '(', ')', ',', 'performs', 'a', 'colon', 'anastomosis', 'ML-powered', 'suturing', 'tool', ',', 'automatically', 'detects', 'patient', '’', 'breathing', 'pattern', 'apply', 'suture', 'correct', 'point.', ',', 'Cloud', 'computing', 'healthcare', 'helped', 'retrieving', 'sharing', 'medical', 'records', 'safely', 'a', 'reduction', 'maintenance', 'costs', '.', 'Through', 'technology', 'doctors', 'healthcare', 'workers', 'access', 'detailed', 'patient', 'data', 'helps', 'speeding', 'analysis', 'ultimately', 'leading', 'care', 'form', 'accurate', 'information', ',', 'medications', ',', 'therapies.', ',', 'How', 'It', 'Biomedical', 'research', '?', ',', 'Since', 'analyze', 'literature', 'readability', ',', 'concise', 'biomedical', 'research', '.', 'With', 'ML', 'algorithms', 'NLP', ',', 'accelerate', 'screening', 'indexing', 'biomedical', 'research', ',', 'ranking', 'literature', 'interest', 'researchers', 'formulate', 'test', 'scientific', 'hypotheses', 'precisely', 'quickly', '.', 'Taking', 'level', ',', 'systems', 'computational', 'modelling', 'assistant', '(', 'CMA', ')', 'helps', 'researchers', 'construct', 'simulation', 'models', 'concepts', 'mind', '.', 'Such', 'innovations', 'majorly', 'contributed', 'topics', 'tumour', 'suppressor', 'mechanisms', 'protein-protein', 'interaction', 'information', 'extraction.', ',', 'precision', 'medicine', ',', 'Since', 'precision', 'medicine', 'focuses', 'healthcare', 'interventions', 'individuals', 'groups', 'patients', 'based', 'profile', ',', 'devices', 'pave', 'practice', 'efficiently', '.', 'With', 'ML', ',', 'complex', 'algorithms', 'large', 'datasets', 'predict', 'create', 'optimal', 'treatment', 'strategy.', ',', 'Deep', 'learning', 'neural', 'networks', 'process', 'data', 'healthcare', 'apps', 'a', 'close', 'watch', 'patient', '’', 'emotional', 'state', ',', 'food', 'intake', ',', 'health', 'monitoring', '.', ',', '“', 'Omics', '”', 'refers', 'collective', 'technologies', 'exploring', 'roles', ',', 'relationships', 'branches', 'ending', 'suffix', '“', 'omics', '”', 'genomics', ',', 'proteomics', ',', '.', 'Omics-based', 'tests', 'based', 'machine', 'learning', 'algorithms', 'find', 'correlations', 'predict', 'treatment', 'responses', ',', 'ultimately', 'creating', 'personalized', 'treatments', 'individual', 'patients', '.', ',', 'How', 'helps', 'psychology', 'neuro', 'patients', ',', 'For', 'psychologists', 'studying', 'creativity', ',', 'promising', 'classes', 'experiments', 'developing', 'data', 'structures', 'programs', 'exploring', 'theories', 'a', 'horizon', '.', 'Studies', 'show', 'conduct', 'therapy', 'sessions', ',', 'e-therapy', 'sessions', ',', 'assessments', 'autonomously', ',', 'assisting', 'human', 'practitioners', ',', ',', 'sessions', '.', 'The', 'Detection', 'Computational', 'Analysis', 'Psychological', 'Signal', 'project', 'ML', ',', 'computer', 'vision', ',', 'NLP', 'analyze', 'language', ',', 'physical', 'gestures', ',', 'social', 'signals', 'identify', 'cues', 'human', 'distress', '.', 'This', 'ground-breaking', 'technology', 'assesses', 'soldiers', 'returning', 'combat', 'recognizes', 'require', 'mental', 'health', 'support', '.', 'In', 'future', ',', 'combine', 'data', 'captured', 'face-to-face', 'interviews', 'information', 'sleeping', ',', 'eating', ',', 'online', 'behaviours', 'a', 'complete', 'patient', 'view.', ',', 'Stroke', 'identification', ',', 'Stroke', 'frequently', 'occurring', 'disease', 'affects', '500', 'million', 'people', 'worldwide', '.', 'Thrombus', ',', 'vessel', 'cerebral', 'infarction', 'major', '(', '85', '%', ')', 'stroke', 'occurrence', '.', 'In', 'recent', 'years', ',', 'techniques', 'numerous', 'stroke-related', 'studies', 'early', 'detection', 'timely', 'treatment', 'efficient', 'outcome', 'prediction', 'solve', 'problem', '.', 'With', 'disposal', ',', 'large', 'amounts', 'data', 'rich', 'information', ',', 'complications', 'real-life', 'clinical', 'questions', 'addressed', 'arena', '.', 'Currently', ',', 'ML', 'algorithms-', 'genetic', 'fuzzy', 'finite', 'state', 'machine', 'PCA', 'implemented', 'build', 'a', 'model', 'building', 'solution', '.', 'These', 'include', 'a', 'human', 'activity', 'recognition', 'stage', 'a', 'stroke', 'onset', 'detection', 'stage', '.', 'An', 'alert', 'stroke', 'message', 'activated', 'a', 'movement', 'significantly', 'normal', 'pattern', 'recorded', '.', 'ML', 'methods', 'applied', 'neuroimaging', 'data', 'assist', 'disease', 'evaluation', 'predicting', 'stroke', 'treatment', 'diagnosis.', ',', 'Patient', 'Monitoring', ',', 'Today', ',', 'market', 'AI-based', 'patient', 'monitoring', 'impressive', 'monetarily', 'enticing', '.', 'It', 'evolving', 'artificial', 'sensors', ',', 'smart', 'technologies', 'explores', 'brain-computer', 'interfaces', 'nanorobotics', '.', 'Companies', 'smart-watches', 'engaged', 'people', 'perform', 'remote', 'monitoring', '“', 'patients', '”', '.', 'An', 'obvious', 'place', 'start', 'wearable', 'embedded', 'sensors', ',', 'glucose', 'monitors', ',', 'pulse', 'monitors', ',', 'oximeters', ',', 'ECG', 'monitors', '.', 'With', 'patient', 'monitoring', 'crucial', ',', 'finds', 'numerous', 'applications', 'chronic', 'conditions', ',', 'intensive', 'care', 'units', ',', 'operating', 'rooms', ',', 'emergency', 'rooms', ',', 'cardiac', 'wards', 'timeless', 'clinical', 'decision-making', 'measured', 'seconds', '.', 'More', 'advances', 'started', 'gain', 'traction', 'smart', 'prosthetics', 'implants', '.', 'These', 'play', 'impeccable', 'role', 'patient', 'management', 'post-surgery', 'rehabilitation', '.', 'Demographics', ',', 'laboratory', 'results', 'vital', 'signs', 'predict', 'cardiac', 'arrest', ',', 'transfer', 'intensive', 'care', 'unit', ',', 'death', '.', 'In', 'addition', ',', 'interpretable', 'machine-learning', 'model', 'assist', 'anesthesiologists', 'predicting', 'hypoxaemia', 'events', 'surgery', '.', 'This', 'suggests', 'deep-learning', 'algorithms', ',', 'raw', 'patient-monitoring', 'data', 'avoid', 'information', 'overload', 'alert', 'overload', 'enabling', 'accurate', 'clinical', 'prediction', 'timely', 'decision-making.', ',', 'Conclusion', ',', 'Considering', 'vast', 'range', 'tasks', ',', 'evident', 'holds', 'deep', 'potential', 'improving', 'patient', 'outcomes', 'skyrocketing', 'levels', '.', 'Using', 'sophisticated', 'algorithms', 'bring', 'a', 'revolution', 'healthcare', 'sector', '.', 'Even', 'facing', 'challenges', 'technology', 'deliver', 'promises', ',', 'ethical', 'measures', ',', 'training', 'physicians', ',', 'standard', 'regulations', ',', 'role', 'transforming', 'clinical', 'practices', '.', 'The', 'biggest', 'challenge', 'integration', 'daily', 'practice', '.', 'All', 'overcome', 'period', 'technologies', 'mature', 'making', 'system', 'enhanced', 'effective', '.', ']']\n"
     ]
    }
   ],
   "source": [
    "print(article_word_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff392dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positivefile=open(\"MasterDictionary\\\\positive-words.txt\",encoding='ISO-8859-1').read()\n",
    "positive_list=list(positivefile.split(\"\\n\"))\n",
    "negativefile=open(\"MasterDictionary\\\\negative-words.txt\",encoding='ISO-8859-1').read()\n",
    "negative_list=list(negativefile.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dfe29e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['healthcare',\n",
       " 'Improve',\n",
       " 'Patient',\n",
       " 'Outcomes',\n",
       " '-',\n",
       " 'Blackcoffer',\n",
       " 'Insights',\n",
       " '[',\n",
       " 'Introduction',\n",
       " ',',\n",
       " '“',\n",
       " 'If',\n",
       " 'kills',\n",
       " '10',\n",
       " 'million',\n",
       " 'people',\n",
       " 'decades',\n",
       " ',',\n",
       " 'a',\n",
       " 'highly',\n",
       " 'infectious',\n",
       " 'virus',\n",
       " 'a',\n",
       " 'war',\n",
       " '.',\n",
       " 'Not',\n",
       " 'missiles',\n",
       " 'microbes.',\n",
       " '”',\n",
       " 'Bill',\n",
       " 'Gates',\n",
       " '’',\n",
       " 'remarks',\n",
       " 'a',\n",
       " 'conference',\n",
       " '2014',\n",
       " ',',\n",
       " 'world',\n",
       " 'avoided',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " '.',\n",
       " 'When',\n",
       " ',',\n",
       " 'unprecedented',\n",
       " ',',\n",
       " 'invisible',\n",
       " 'virus',\n",
       " 'hit',\n",
       " ',',\n",
       " 'met',\n",
       " 'overwhelmed',\n",
       " 'unprepared',\n",
       " 'healthcare',\n",
       " 'system',\n",
       " 'oblivious',\n",
       " 'population',\n",
       " '.',\n",
       " 'This',\n",
       " 'public',\n",
       " 'health',\n",
       " 'emergency',\n",
       " 'demonstrated',\n",
       " 'lack',\n",
       " 'scientific',\n",
       " 'consideration',\n",
       " 'underlined',\n",
       " 'alarming',\n",
       " 'robust',\n",
       " 'innovations',\n",
       " 'health',\n",
       " 'medical',\n",
       " 'facilities',\n",
       " '.',\n",
       " 'For',\n",
       " 'past',\n",
       " 'years',\n",
       " ',',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'proven',\n",
       " 'tangible',\n",
       " 'potential',\n",
       " 'healthcare',\n",
       " 'sectors',\n",
       " ',',\n",
       " 'clinical',\n",
       " 'practices',\n",
       " ',',\n",
       " 'translational',\n",
       " 'medical',\n",
       " 'biomedical',\n",
       " 'research.',\n",
       " ',',\n",
       " 'After',\n",
       " 'case',\n",
       " 'detected',\n",
       " 'China',\n",
       " 'December',\n",
       " '31st',\n",
       " '2019',\n",
       " ',',\n",
       " 'program',\n",
       " 'developed',\n",
       " 'BlueDot',\n",
       " 'alerted',\n",
       " 'world',\n",
       " 'pandemic',\n",
       " '.',\n",
       " 'It',\n",
       " 'quick',\n",
       " 'realise',\n",
       " '’',\n",
       " 'ability',\n",
       " 'analyse',\n",
       " 'large',\n",
       " 'chunks',\n",
       " 'data',\n",
       " 'detecting',\n",
       " 'patterns',\n",
       " 'identifying',\n",
       " 'tracking',\n",
       " 'carriers',\n",
       " 'virus.',\n",
       " ',',\n",
       " 'Many',\n",
       " 'tracing',\n",
       " 'apps',\n",
       " 'tabs',\n",
       " 'people',\n",
       " 'infected',\n",
       " 'prevent',\n",
       " 'risk',\n",
       " 'cross-infection',\n",
       " 'algorithms',\n",
       " 'track',\n",
       " 'patterns',\n",
       " 'extract',\n",
       " 'features',\n",
       " 'classify',\n",
       " 'categorise',\n",
       " 'them.',\n",
       " ',',\n",
       " 'So',\n",
       " '?',\n",
       " ',',\n",
       " 'IBM',\n",
       " 'Watson',\n",
       " ',',\n",
       " 'a',\n",
       " 'sophisticated',\n",
       " 'works',\n",
       " 'cloud',\n",
       " 'computing',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " ',',\n",
       " 'prominently',\n",
       " 'contributed',\n",
       " 'healthcare',\n",
       " 'sector',\n",
       " 'a',\n",
       " 'global',\n",
       " 'level',\n",
       " '.',\n",
       " 'Being',\n",
       " 'a',\n",
       " 'conversational',\n",
       " ',',\n",
       " '2013',\n",
       " ',',\n",
       " 'Watson',\n",
       " 'helped',\n",
       " 'recommending',\n",
       " 'treatments',\n",
       " 'patients',\n",
       " 'suffering',\n",
       " 'cancer',\n",
       " 'ensure',\n",
       " 'treatment',\n",
       " 'optimum',\n",
       " 'costs.',\n",
       " ',',\n",
       " 'Researchers',\n",
       " 'Google',\n",
       " 'Inc.',\n",
       " 'showed',\n",
       " 'system',\n",
       " 'trained',\n",
       " 'thousands',\n",
       " 'images',\n",
       " 'achieve',\n",
       " 'physician-level',\n",
       " 'sensitivity.',\n",
       " ',',\n",
       " 'By',\n",
       " 'identifying',\n",
       " 'molecular',\n",
       " 'patterns',\n",
       " 'disease',\n",
       " 'status',\n",
       " 'subtypes',\n",
       " ',',\n",
       " 'gene',\n",
       " 'expression',\n",
       " ',',\n",
       " 'protein',\n",
       " 'abundance',\n",
       " 'levels',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'methods',\n",
       " 'detect',\n",
       " 'fatal',\n",
       " 'diseases',\n",
       " 'cancer',\n",
       " 'early',\n",
       " 'stage',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " '(',\n",
       " 'ML',\n",
       " ')',\n",
       " 'techniques',\n",
       " 'focus',\n",
       " 'analyzing',\n",
       " 'structured',\n",
       " 'data',\n",
       " ',',\n",
       " 'clustering',\n",
       " 'patients',\n",
       " '’',\n",
       " 'traits',\n",
       " 'infer',\n",
       " 'probability',\n",
       " 'disease',\n",
       " 'outcomes',\n",
       " '.',\n",
       " 'Since',\n",
       " 'patient',\n",
       " 'traits',\n",
       " 'include',\n",
       " 'masses',\n",
       " 'data',\n",
       " 'relating',\n",
       " 'age',\n",
       " ',',\n",
       " 'gender',\n",
       " ',',\n",
       " 'disease',\n",
       " 'history',\n",
       " ',',\n",
       " 'disease-specific',\n",
       " 'data',\n",
       " 'diagnostic',\n",
       " 'imaging',\n",
       " 'gene',\n",
       " 'expressions',\n",
       " ',',\n",
       " ',',\n",
       " 'ML',\n",
       " 'extract',\n",
       " 'features',\n",
       " 'data',\n",
       " 'inputs',\n",
       " 'constructing',\n",
       " 'data',\n",
       " 'analytical',\n",
       " 'algorithms.',\n",
       " ',',\n",
       " 'ML',\n",
       " 'algorithms',\n",
       " 'supervised',\n",
       " 'unsupervised',\n",
       " '.',\n",
       " 'Unsupervised',\n",
       " 'learning',\n",
       " 'helps',\n",
       " 'extracting',\n",
       " 'features',\n",
       " 'clustering',\n",
       " 'similar',\n",
       " 'features',\n",
       " 'leads',\n",
       " 'early',\n",
       " 'detection',\n",
       " 'diseases',\n",
       " '.',\n",
       " 'Clustering',\n",
       " 'principal',\n",
       " 'component',\n",
       " 'analysis',\n",
       " 'enable',\n",
       " 'grouping',\n",
       " 'clustering',\n",
       " 'similar',\n",
       " 'traits',\n",
       " 'maximize',\n",
       " 'minimize',\n",
       " 'similarity',\n",
       " 'patients',\n",
       " 'clusters',\n",
       " '.',\n",
       " 'Since',\n",
       " 'patient',\n",
       " 'traits',\n",
       " 'recorded',\n",
       " 'multiple',\n",
       " 'dimensions',\n",
       " ',',\n",
       " 'genes',\n",
       " ',',\n",
       " 'principal',\n",
       " 'component',\n",
       " 'analysis',\n",
       " '(',\n",
       " 'PCA',\n",
       " ')',\n",
       " 'creates',\n",
       " 'apparatus',\n",
       " 'reduce',\n",
       " 'dimensions',\n",
       " 'humans',\n",
       " 'alone.',\n",
       " ',',\n",
       " 'Supervised',\n",
       " 'learning',\n",
       " 'considers',\n",
       " 'outcomes',\n",
       " 'subjects',\n",
       " 'traits',\n",
       " ',',\n",
       " 'correlates',\n",
       " 'inputs',\n",
       " 'outputs',\n",
       " 'predict',\n",
       " 'probability',\n",
       " 'a',\n",
       " 'clinical',\n",
       " 'event',\n",
       " ',',\n",
       " 'expected',\n",
       " 'a',\n",
       " 'disease',\n",
       " 'level',\n",
       " 'expected',\n",
       " 'survival',\n",
       " 'time',\n",
       " ',',\n",
       " 'risk',\n",
       " 'Down',\n",
       " '’',\n",
       " 'syndrome.',\n",
       " ',',\n",
       " 'Biomarker',\n",
       " 'panels',\n",
       " 'detect',\n",
       " 'ovarian',\n",
       " 'cancer',\n",
       " ',',\n",
       " 'outperformed',\n",
       " 'conventional',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'due',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'In',\n",
       " 'addition',\n",
       " ',',\n",
       " 'EHRs',\n",
       " 'Bayesian',\n",
       " 'networks',\n",
       " ',',\n",
       " 'a',\n",
       " 'part',\n",
       " 'supervised',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " ',',\n",
       " 'predict',\n",
       " 'clinical',\n",
       " 'outcomes',\n",
       " 'mortality',\n",
       " 'respectively.',\n",
       " ',',\n",
       " 'Unstructured',\n",
       " 'data',\n",
       " 'clinical',\n",
       " 'notes',\n",
       " 'texts',\n",
       " 'converted',\n",
       " 'machine-readable',\n",
       " 'structured',\n",
       " 'data',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'works',\n",
       " 'components',\n",
       " ':',\n",
       " 'text',\n",
       " 'processing',\n",
       " 'classification',\n",
       " '.',\n",
       " 'Text',\n",
       " 'processing',\n",
       " 'helps',\n",
       " 'identifying',\n",
       " 'a',\n",
       " 'series',\n",
       " 'disease-relevant',\n",
       " 'keywords',\n",
       " 'clinical',\n",
       " 'notes',\n",
       " 'classification',\n",
       " 'categorized',\n",
       " 'normal',\n",
       " 'abnormal',\n",
       " 'cases',\n",
       " '.',\n",
       " 'Chest',\n",
       " 'screening',\n",
       " 'ML',\n",
       " 'NLP',\n",
       " 'helped',\n",
       " 'find',\n",
       " 'abnormalities',\n",
       " 'lungs',\n",
       " 'provide',\n",
       " 'treatment',\n",
       " 'covid',\n",
       " 'patients',\n",
       " '.',\n",
       " 'Healthcare',\n",
       " 'organizations',\n",
       " 'NLP-based',\n",
       " 'chatbots',\n",
       " 'increase',\n",
       " 'interactions',\n",
       " 'patients',\n",
       " ',',\n",
       " 'keeping',\n",
       " 'mental',\n",
       " 'health',\n",
       " 'wellness',\n",
       " 'check.',\n",
       " ',',\n",
       " 'Deep',\n",
       " 'learning',\n",
       " 'a',\n",
       " 'modern',\n",
       " 'extension',\n",
       " 'classical',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'techniques',\n",
       " 'helps',\n",
       " 'explore',\n",
       " 'complex',\n",
       " 'non-linear',\n",
       " 'patterns',\n",
       " 'data',\n",
       " ',',\n",
       " 'algorithms',\n",
       " 'convolution',\n",
       " 'neural',\n",
       " 'network',\n",
       " ',',\n",
       " 'recurrent',\n",
       " 'neural',\n",
       " 'network',\n",
       " ',',\n",
       " 'deep',\n",
       " 'belief',\n",
       " 'network',\n",
       " ',',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'enables',\n",
       " 'accurate',\n",
       " 'clinical',\n",
       " 'prediction',\n",
       " '.',\n",
       " 'When',\n",
       " 'genome',\n",
       " 'interpretation',\n",
       " ',',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'surpass',\n",
       " 'conventional',\n",
       " 'methods',\n",
       " 'logistics',\n",
       " 'regression',\n",
       " 'support',\n",
       " 'vector',\n",
       " 'machines.',\n",
       " ',',\n",
       " 'Sepsis',\n",
       " 'Watch',\n",
       " 'system',\n",
       " 'trained',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'holds',\n",
       " 'capability',\n",
       " 'analyze',\n",
       " '32',\n",
       " 'million',\n",
       " 'data',\n",
       " 'points',\n",
       " 'create',\n",
       " 'a',\n",
       " 'patient',\n",
       " '’',\n",
       " 'risk',\n",
       " 'score',\n",
       " 'identify',\n",
       " 'early',\n",
       " 'stages',\n",
       " 'sepsis.',\n",
       " ',',\n",
       " 'Another',\n",
       " 'method',\n",
       " 'Learning-based',\n",
       " 'Optimization',\n",
       " 'Under',\n",
       " 'Sampling',\n",
       " 'Pattern',\n",
       " '(',\n",
       " 'LOUPE',\n",
       " ')',\n",
       " 'based',\n",
       " 'integrating',\n",
       " 'full',\n",
       " 'resolution',\n",
       " 'MRI',\n",
       " 'scans',\n",
       " 'convolutional',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'algorithm',\n",
       " ',',\n",
       " 'helps',\n",
       " 'creating',\n",
       " 'accurate',\n",
       " 'reconstructions.',\n",
       " ',',\n",
       " 'Robotic',\n",
       " 'surgery',\n",
       " 'widely',\n",
       " 'considered',\n",
       " 'delicate',\n",
       " 'surgeries',\n",
       " 'gynaecology',\n",
       " 'prostate',\n",
       " 'surgery',\n",
       " '.',\n",
       " 'Even',\n",
       " 'striking',\n",
       " 'balance',\n",
       " 'human',\n",
       " 'decisions',\n",
       " 'precision',\n",
       " ',',\n",
       " 'robotic',\n",
       " 'surgery',\n",
       " 'reduces',\n",
       " 'surgeon',\n",
       " 'efficiency',\n",
       " 'manually',\n",
       " 'operated',\n",
       " 'a',\n",
       " 'console',\n",
       " '.',\n",
       " 'Thus',\n",
       " ',',\n",
       " 'autonomous',\n",
       " 'robotic',\n",
       " 'surgery',\n",
       " 'rise',\n",
       " 'inventions',\n",
       " 'robotic',\n",
       " 'silicon',\n",
       " 'fingers',\n",
       " 'mimic',\n",
       " 'sense',\n",
       " 'touch',\n",
       " 'surgeons',\n",
       " 'identify',\n",
       " 'organs',\n",
       " ',',\n",
       " 'cut',\n",
       " 'tissues',\n",
       " ',',\n",
       " 'etc.',\n",
       " ',',\n",
       " 'robotic',\n",
       " 'catheters',\n",
       " 'navigate',\n",
       " 'touching',\n",
       " 'blood',\n",
       " ',',\n",
       " 'tissue',\n",
       " ',',\n",
       " 'valve.',\n",
       " ',',\n",
       " 'Researchers',\n",
       " 'Children',\n",
       " '’',\n",
       " 'National',\n",
       " 'Hospital',\n",
       " ',',\n",
       " 'Washington',\n",
       " 'developed',\n",
       " 'called',\n",
       " 'Smart',\n",
       " 'Tissue',\n",
       " 'Autonomous',\n",
       " 'Robot',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " 'performs',\n",
       " 'a',\n",
       " 'colon',\n",
       " 'anastomosis',\n",
       " 'ML-powered',\n",
       " 'suturing',\n",
       " 'tool',\n",
       " ',',\n",
       " 'automatically',\n",
       " 'detects',\n",
       " 'patient',\n",
       " '’',\n",
       " 'breathing',\n",
       " 'pattern',\n",
       " 'apply',\n",
       " 'suture',\n",
       " 'correct',\n",
       " 'point.',\n",
       " ',',\n",
       " 'Cloud',\n",
       " 'computing',\n",
       " 'healthcare',\n",
       " 'helped',\n",
       " 'retrieving',\n",
       " 'sharing',\n",
       " 'medical',\n",
       " 'records',\n",
       " 'safely',\n",
       " 'a',\n",
       " 'reduction',\n",
       " 'maintenance',\n",
       " 'costs',\n",
       " '.',\n",
       " 'Through',\n",
       " 'technology',\n",
       " 'doctors',\n",
       " 'healthcare',\n",
       " 'workers',\n",
       " 'access',\n",
       " 'detailed',\n",
       " 'patient',\n",
       " 'data',\n",
       " 'helps',\n",
       " 'speeding',\n",
       " 'analysis',\n",
       " 'ultimately',\n",
       " 'leading',\n",
       " 'care',\n",
       " 'form',\n",
       " 'accurate',\n",
       " 'information',\n",
       " ',',\n",
       " 'medications',\n",
       " ',',\n",
       " 'therapies.',\n",
       " ',',\n",
       " 'How',\n",
       " 'It',\n",
       " 'Biomedical',\n",
       " 'research',\n",
       " '?',\n",
       " ',',\n",
       " 'Since',\n",
       " 'analyze',\n",
       " 'literature',\n",
       " 'readability',\n",
       " ',',\n",
       " 'concise',\n",
       " 'biomedical',\n",
       " 'research',\n",
       " '.',\n",
       " 'With',\n",
       " 'ML',\n",
       " 'algorithms',\n",
       " 'NLP',\n",
       " ',',\n",
       " 'accelerate',\n",
       " 'screening',\n",
       " 'indexing',\n",
       " 'biomedical',\n",
       " 'research',\n",
       " ',',\n",
       " 'ranking',\n",
       " 'literature',\n",
       " 'interest',\n",
       " 'researchers',\n",
       " 'formulate',\n",
       " 'test',\n",
       " 'scientific',\n",
       " 'hypotheses',\n",
       " 'precisely',\n",
       " 'quickly',\n",
       " '.',\n",
       " 'Taking',\n",
       " 'level',\n",
       " ',',\n",
       " 'systems',\n",
       " 'computational',\n",
       " 'modelling',\n",
       " 'assistant',\n",
       " '(',\n",
       " 'CMA',\n",
       " ')',\n",
       " 'helps',\n",
       " 'researchers',\n",
       " 'construct',\n",
       " 'simulation',\n",
       " 'models',\n",
       " 'concepts',\n",
       " 'mind',\n",
       " '.',\n",
       " 'Such',\n",
       " 'innovations',\n",
       " 'majorly',\n",
       " 'contributed',\n",
       " 'topics',\n",
       " 'tumour',\n",
       " 'suppressor',\n",
       " 'mechanisms',\n",
       " 'protein-protein',\n",
       " 'interaction',\n",
       " 'information',\n",
       " 'extraction.',\n",
       " ',',\n",
       " 'precision',\n",
       " 'medicine',\n",
       " ',',\n",
       " 'Since',\n",
       " 'precision',\n",
       " 'medicine',\n",
       " 'focuses',\n",
       " 'healthcare',\n",
       " 'interventions',\n",
       " 'individuals',\n",
       " 'groups',\n",
       " 'patients',\n",
       " 'based',\n",
       " 'profile',\n",
       " ',',\n",
       " 'devices',\n",
       " 'pave',\n",
       " 'practice',\n",
       " 'efficiently',\n",
       " '.',\n",
       " 'With',\n",
       " 'ML',\n",
       " ',',\n",
       " 'complex',\n",
       " 'algorithms',\n",
       " 'large',\n",
       " 'datasets',\n",
       " 'predict',\n",
       " 'create',\n",
       " 'optimal',\n",
       " 'treatment',\n",
       " 'strategy.',\n",
       " ',',\n",
       " 'Deep',\n",
       " 'learning',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'process',\n",
       " 'data',\n",
       " 'healthcare',\n",
       " 'apps',\n",
       " 'a',\n",
       " 'close',\n",
       " 'watch',\n",
       " 'patient',\n",
       " '’',\n",
       " 'emotional',\n",
       " 'state',\n",
       " ',',\n",
       " 'food',\n",
       " 'intake',\n",
       " ',',\n",
       " 'health',\n",
       " 'monitoring',\n",
       " '.',\n",
       " ',',\n",
       " '“',\n",
       " 'Omics',\n",
       " '”',\n",
       " 'refers',\n",
       " 'collective',\n",
       " 'technologies',\n",
       " 'exploring',\n",
       " 'roles',\n",
       " ',',\n",
       " 'relationships',\n",
       " 'branches',\n",
       " 'ending',\n",
       " 'suffix',\n",
       " '“',\n",
       " 'omics',\n",
       " '”',\n",
       " 'genomics',\n",
       " ',',\n",
       " 'proteomics',\n",
       " ',',\n",
       " '.',\n",
       " 'Omics-based',\n",
       " 'tests',\n",
       " 'based',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'find',\n",
       " 'correlations',\n",
       " 'predict',\n",
       " 'treatment',\n",
       " 'responses',\n",
       " ',',\n",
       " 'ultimately',\n",
       " 'creating',\n",
       " 'personalized',\n",
       " 'treatments',\n",
       " 'individual',\n",
       " 'patients',\n",
       " '.',\n",
       " ',',\n",
       " 'How',\n",
       " 'helps',\n",
       " 'psychology',\n",
       " 'neuro',\n",
       " 'patients',\n",
       " ',',\n",
       " 'For',\n",
       " 'psychologists',\n",
       " 'studying',\n",
       " 'creativity',\n",
       " ',',\n",
       " 'promising',\n",
       " 'classes',\n",
       " 'experiments',\n",
       " 'developing',\n",
       " 'data',\n",
       " 'structures',\n",
       " 'programs',\n",
       " 'exploring',\n",
       " 'theories',\n",
       " 'a',\n",
       " 'horizon',\n",
       " '.',\n",
       " 'Studies',\n",
       " 'show',\n",
       " 'conduct',\n",
       " 'therapy',\n",
       " 'sessions',\n",
       " ',',\n",
       " 'e-therapy',\n",
       " 'sessions',\n",
       " ',',\n",
       " 'assessments',\n",
       " 'autonomously',\n",
       " ',',\n",
       " 'assisting',\n",
       " 'human',\n",
       " 'practitioners',\n",
       " ',',\n",
       " ',',\n",
       " 'sessions',\n",
       " '.',\n",
       " 'The',\n",
       " 'Detection',\n",
       " 'Computational',\n",
       " 'Analysis',\n",
       " 'Psychological',\n",
       " 'Signal',\n",
       " 'project',\n",
       " 'ML',\n",
       " ',',\n",
       " 'computer',\n",
       " 'vision',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'analyze',\n",
       " 'language',\n",
       " ',',\n",
       " 'physical',\n",
       " 'gestures',\n",
       " ',',\n",
       " 'social',\n",
       " 'signals',\n",
       " 'identify',\n",
       " 'cues',\n",
       " 'human',\n",
       " 'distress',\n",
       " '.',\n",
       " 'This',\n",
       " 'ground-breaking',\n",
       " 'technology',\n",
       " 'assesses',\n",
       " 'soldiers',\n",
       " 'returning',\n",
       " 'combat',\n",
       " 'recognizes',\n",
       " 'require',\n",
       " 'mental',\n",
       " 'health',\n",
       " 'support',\n",
       " '.',\n",
       " 'In',\n",
       " 'future',\n",
       " ',',\n",
       " 'combine',\n",
       " 'data',\n",
       " 'captured',\n",
       " 'face-to-face',\n",
       " 'interviews',\n",
       " 'information',\n",
       " 'sleeping',\n",
       " ',',\n",
       " 'eating',\n",
       " ',',\n",
       " 'online',\n",
       " 'behaviours',\n",
       " 'a',\n",
       " 'complete',\n",
       " 'patient',\n",
       " 'view.',\n",
       " ',',\n",
       " 'Stroke',\n",
       " 'identification',\n",
       " ',',\n",
       " 'Stroke',\n",
       " 'frequently',\n",
       " 'occurring',\n",
       " 'disease',\n",
       " 'affects',\n",
       " '500',\n",
       " 'million',\n",
       " 'people',\n",
       " 'worldwide',\n",
       " '.',\n",
       " 'Thrombus',\n",
       " ',',\n",
       " 'vessel',\n",
       " 'cerebral',\n",
       " 'infarction',\n",
       " 'major',\n",
       " '(',\n",
       " '85',\n",
       " '%',\n",
       " ')',\n",
       " 'stroke',\n",
       " 'occurrence',\n",
       " '.',\n",
       " 'In',\n",
       " 'recent',\n",
       " 'years',\n",
       " ',',\n",
       " 'techniques',\n",
       " 'numerous',\n",
       " 'stroke-related',\n",
       " 'studies',\n",
       " 'early',\n",
       " 'detection',\n",
       " 'timely',\n",
       " 'treatment',\n",
       " 'efficient',\n",
       " 'outcome',\n",
       " 'prediction',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_word_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6217a0",
   "metadata": {},
   "source": [
    "#### Calculating Sentiment Analysis using positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "707e5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_score_list = list()\n",
    "negative_score_list = list()\n",
    "polarity_list=list()\n",
    "subjectivity_list=list()\n",
    "for article_words in article_word_list:\n",
    "    positive_score=len([words for words in article_words if words in list(positive_list)])\n",
    "    negative_score=len([words for words in article_words if words in list(negative_list)])\n",
    "    polarity=((positive_score-negative_score)/((positive_score+negative_score)+0.000001))\n",
    "    subjectivity=((positive_score+negative_score)/((len(article_words))+0.000001))\n",
    "    positive_score_list.append(positive_score)\n",
    "    negative_score_list.append(negative_score)\n",
    "    polarity_list.append(polarity)\n",
    "    subjectivity_list.append(subjectivity)\n",
    "output_df[\"POSITIVE SCORE\"]=positive_score_list\n",
    "output_df[\"NEGATIVE SCORE\"]=negative_score_list\n",
    "output_df[\"POLARITY SCORE\"]=polarity_list\n",
    "output_df[\"SUBJECTIVITY SCORE\"]=subjectivity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a8a1064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes -...</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.072812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.100552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.084615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.079415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Will AI Replace Us or Work With Us? - Blackcof...</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "\n",
       "                                                text  POSITIVE SCORE  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes -...              63   \n",
       "1  What if the Creation is Taking Over the Creato...              55   \n",
       "2  What Jobs Will Robots Take From Humans in The ...              65   \n",
       "3  Will Machine Replace The Human in the Future o...              55   \n",
       "4  Will AI Replace Us or Work With Us? - Blackcof...              48   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \n",
       "0              31        0.340426            0.072812  \n",
       "1              36        0.208791            0.100552  \n",
       "2              34        0.313131            0.084615  \n",
       "3              21        0.447368            0.079415  \n",
       "4              22        0.371429            0.060606  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00deb3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_nltk=stopwords.words('english')\n",
    "stop_words_nltk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbdfeaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(article_text):\n",
    "    return re.sub(r'[^\\w]', ' ', article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a08ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[\"processed_article_text\"]=output_df[\"text\"].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae7a2e",
   "metadata": {},
   "source": [
    "#### Functions for removing nltk stopwords and counting personal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f2741d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(article_text):\n",
    "    cleanword=article_text.split()\n",
    "    clean_words_list = [word for word in cleanword if word not in stop_words_nltk]\n",
    "    return clean_words_list\n",
    "def clean_word_count(article_text):\n",
    "    return len(clean_words(article_text))\n",
    "def personal_pronouns(article_text):\n",
    "    pattern=re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b')\n",
    "    personal_pronouns_list=(re.findall(pattern, article_text))\n",
    "    return personal_pronouns_list\n",
    "def personal_pronouns_count(article_text):\n",
    "    return len(personal_pronouns(article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30011490",
   "metadata": {},
   "source": [
    "#### Testing the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3f738af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'name', 'gaurav', 'tomar,', 'stop', 'word', 'us', 'US', 'transparency'] 9\n",
      "['my', 'us'] 2\n"
     ]
    }
   ],
   "source": [
    "w=\"hello my name is gaurav tomar, this is a stop word us US transparency\"\n",
    "clean_word_list = clean_words(w)\n",
    "personal_pronouns_list = personal_pronouns(w)\n",
    "print(clean_word_list, len(clean_word_list))\n",
    "print(personal_pronouns_list, len(personal_pronouns_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd1dd7",
   "metadata": {},
   "source": [
    "#### Applying these functions to the output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b7aa970",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[\"clean_words\"]=output_df[\"processed_article_text\"].apply(clean_words)\n",
    "output_df[\"personal_pronouns_text\"]=output_df[\"processed_article_text\"].apply(personal_pronouns)\n",
    "output_df[\"WORD COUNT\"]=output_df[\"processed_article_text\"].apply(clean_word_count)\n",
    "output_df[\"PERSONAL PRONOUNS\"]=output_df[\"processed_article_text\"].apply(personal_pronouns_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff944c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>processed_article_text</th>\n",
       "      <th>clean_words</th>\n",
       "      <th>personal_pronouns_text</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes -...</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes  ...</td>\n",
       "      <td>[AI, healthcare, Improve, Patient, Outcomes, B...</td>\n",
       "      <td>[us]</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "\n",
       "                                                text  POSITIVE SCORE  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes -...              63   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0              31        0.340426            0.072812   \n",
       "\n",
       "                              processed_article_text  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes  ...   \n",
       "\n",
       "                                         clean_words personal_pronouns_text  \\\n",
       "0  [AI, healthcare, Improve, Patient, Outcomes, B...                   [us]   \n",
       "\n",
       "   WORD COUNT  PERSONAL PRONOUNS  \n",
       "0        1203                  1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3471d91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>processed_article_text</th>\n",
       "      <th>clean_words</th>\n",
       "      <th>personal_pronouns_text</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes -...</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes  ...</td>\n",
       "      <td>[AI, healthcare, Improve, Patient, Outcomes, B...</td>\n",
       "      <td>[us]</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.100552</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>[What, Creation, Taking, Over, Creator, Blackc...</td>\n",
       "      <td>[we, us, us, us, we, we]</td>\n",
       "      <td>809</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>[What, Jobs, Will, Robots, Take, From, Humans,...</td>\n",
       "      <td>[us, us]</td>\n",
       "      <td>1051</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.079415</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>[Will, Machine, Replace, The, Human, Future, W...</td>\n",
       "      <td>[us, we, us, we, we, we, we, we, we, we, we, w...</td>\n",
       "      <td>943</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Will AI Replace Us or Work With Us? - Blackcof...</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>Will AI Replace Us or Work With Us    Blackcof...</td>\n",
       "      <td>[Will, AI, Replace, Us, Work, With, Us, Blackc...</td>\n",
       "      <td>[us, we, we, we, we, us, us, we, we, us, us, us]</td>\n",
       "      <td>1034</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "\n",
       "                                                text  POSITIVE SCORE  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes -...              63   \n",
       "1  What if the Creation is Taking Over the Creato...              55   \n",
       "2  What Jobs Will Robots Take From Humans in The ...              65   \n",
       "3  Will Machine Replace The Human in the Future o...              55   \n",
       "4  Will AI Replace Us or Work With Us? - Blackcof...              48   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0              31        0.340426            0.072812   \n",
       "1              36        0.208791            0.100552   \n",
       "2              34        0.313131            0.084615   \n",
       "3              21        0.447368            0.079415   \n",
       "4              22        0.371429            0.060606   \n",
       "\n",
       "                              processed_article_text  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes  ...   \n",
       "1  What if the Creation is Taking Over the Creato...   \n",
       "2  What Jobs Will Robots Take From Humans in The ...   \n",
       "3  Will Machine Replace The Human in the Future o...   \n",
       "4  Will AI Replace Us or Work With Us    Blackcof...   \n",
       "\n",
       "                                         clean_words  \\\n",
       "0  [AI, healthcare, Improve, Patient, Outcomes, B...   \n",
       "1  [What, Creation, Taking, Over, Creator, Blackc...   \n",
       "2  [What, Jobs, Will, Robots, Take, From, Humans,...   \n",
       "3  [Will, Machine, Replace, The, Human, Future, W...   \n",
       "4  [Will, AI, Replace, Us, Work, With, Us, Blackc...   \n",
       "\n",
       "                              personal_pronouns_text  WORD COUNT  \\\n",
       "0                                               [us]        1203   \n",
       "1                           [we, us, us, us, we, we]         809   \n",
       "2                                           [us, us]        1051   \n",
       "3  [us, we, us, we, we, we, we, we, we, we, we, w...         943   \n",
       "4   [us, we, we, we, we, us, us, we, we, us, us, us]        1034   \n",
       "\n",
       "   PERSONAL PRONOUNS  \n",
       "0                  1  \n",
       "1                  6  \n",
       "2                  2  \n",
       "3                 17  \n",
       "4                 12  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c816e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(article_text):\n",
    "    article_words = article_text.split()\n",
    "    average_word_length = ((sum(len(word) for word in article_words)) / len(article_words))\n",
    "    return average_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39f721c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(avg_word_length(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4e68797",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[\"AVG WORD LENGTH\"]=output_df[\"processed_article_text\"].fillna(\"\").apply(avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ad40c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>processed_article_text</th>\n",
       "      <th>clean_words</th>\n",
       "      <th>personal_pronouns_text</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes -...</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes  ...</td>\n",
       "      <td>[AI, healthcare, Improve, Patient, Outcomes, B...</td>\n",
       "      <td>[us]</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>5.556962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "\n",
       "                                                text  POSITIVE SCORE  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes -...              63   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0              31        0.340426            0.072812   \n",
       "\n",
       "                              processed_article_text  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes  ...   \n",
       "\n",
       "                                         clean_words personal_pronouns_text  \\\n",
       "0  [AI, healthcare, Improve, Patient, Outcomes, B...                   [us]   \n",
       "\n",
       "   WORD COUNT  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0        1203                  1         5.556962  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89e3bf",
   "metadata": {},
   "source": [
    "#### Function to count the syllabels in a given word, this code is not mine and it is taken from: {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e752442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sylco(article_text) :\n",
    "    word = article_text.lower()\n",
    "\n",
    "    # exception_add are words that need extra syllables\n",
    "    # exception_del are words that need less syllables\n",
    "\n",
    "    exception_add = ['serious','crucial']\n",
    "    exception_del = ['fortunately','unfortunately']\n",
    "\n",
    "    co_one = ['cool','coach','coat','coal','count','coin','coarse','coup','coif','cook','coign','coiffe','coof','court']\n",
    "    co_two = ['coapt','coed','coinci']\n",
    "\n",
    "    pre_one = ['preach']\n",
    "\n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number\n",
    "\n",
    "    #1) if letters < 3 : return 1\n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    "\n",
    "    #2) if doesn't end with \"ted\" or \"tes\" or \"ses\" or \"ied\" or \"ies\", discard \"es\" and \"ed\" at the end.\n",
    "    # if it has only 1 vowel or 1 set of consecutive vowels, discard. (like \"speed\", \"fled\" etc.)\n",
    "\n",
    "    if word[-2:] == \"es\" or word[-2:] == \"ed\" :\n",
    "        doubleAndtripple_1 = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "        if doubleAndtripple_1 > 1 or len(re.findall(r'[eaoui][^eaoui]',word)) > 1 :\n",
    "            if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "            else :\n",
    "                disc+=1\n",
    "\n",
    "    #3) discard trailing \"e\", except where ending is \"le\"  \n",
    "\n",
    "    le_except = ['whole','mobile','pole','male','female','hale','pale','tale','sale','aisle','whale','while']\n",
    "\n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\" and word not in le_except :\n",
    "            pass\n",
    "\n",
    "        else :\n",
    "            disc+=1\n",
    "\n",
    "    #4) check if consecutive vowels exists, triplets or pairs, count them as one.\n",
    "\n",
    "    doubleAndtripple = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "    tripple = len(re.findall(r'[eaoui][eaoui][eaoui]',word))\n",
    "    disc+=doubleAndtripple + tripple\n",
    "\n",
    "    #5) count remaining vowels in word.\n",
    "    numVowels = len(re.findall(r'[eaoui]',word))\n",
    "\n",
    "    #6) add one if starts with \"mc\"\n",
    "    if word[:2] == \"mc\" :\n",
    "        syls+=1\n",
    "\n",
    "    #7) add one if ends with \"y\" but is not surrouned by vowel\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    "\n",
    "    #8) add one if \"y\" is surrounded by non-vowels and is not in the last word.\n",
    "\n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "\n",
    "    #9) if starts with \"tri-\" or \"bi-\" and is followed by a vowel, add one.\n",
    "\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    #10) if ends with \"-ian\", should be counted as two syllables, except for \"-tian\" and \"-cian\"\n",
    "\n",
    "    if word[-3:] == \"ian\" : \n",
    "    #and (word[-4:] != \"cian\" or word[-4:] != \"tian\") :\n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #11) if starts with \"co-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:2] == \"co\" and word[2] in 'eaoui' :\n",
    "\n",
    "        if word[:4] in co_two or word[:5] in co_two or word[:6] in co_two :\n",
    "            syls+=1\n",
    "        elif word[:4] in co_one or word[:5] in co_one or word[:6] in co_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #12) if starts with \"pre-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:3] == \"pre\" and word[3] in 'eaoui' :\n",
    "        if word[:6] in pre_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #13) check for \"-n't\" and cross match with dictionary to add syllable.\n",
    "\n",
    "    negative = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\",\"wouldn't\"]\n",
    "\n",
    "    if word[-3:] == \"n't\" :\n",
    "        if word in negative :\n",
    "            syls+=1\n",
    "        else :\n",
    "            pass   \n",
    "\n",
    "    #14) Handling the exceptional words.\n",
    "\n",
    "    if word in exception_del :\n",
    "        disc+=1\n",
    "\n",
    "    if word in exception_add :\n",
    "        syls+=1     \n",
    "\n",
    "    # calculate the output\n",
    "    syllable_count=numVowels - disc + syls\n",
    "    return syllable_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b61d4",
   "metadata": {},
   "source": [
    "#### Function to find number of syllables per word (as the explanation was not clear so i calculated average syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53af0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_syl_per_word(article_text):\n",
    "    word_syll_map = dict()\n",
    "    for word  in article_text.split():\n",
    "        word_syll_map[word] = sylco(word)\n",
    "    avg_syl = sum(list(word_syll_map.values()))/len(list(word_syll_map.keys()))\n",
    "    return avg_syl\n",
    "output_df[\"SYLLABLE PER WORD\"]=output_df[\"processed_article_text\"].apply(avg_syl_per_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17912ae6",
   "metadata": {},
   "source": [
    "#### Function to find number of Complex Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82528620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_complex_words(article_text):\n",
    "    complex_word_count = [word for word in article_text.split() if sylco(word)>2]\n",
    "    return complex_word_count\n",
    "def number_of_complex_words(article_text):\n",
    "    return len(find_complex_words(article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405d502",
   "metadata": {},
   "source": [
    "#### Adding the complex words and number of complex words to the output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "225300cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[\"complex_words\"]=output_df[\"processed_article_text\"].apply(find_complex_words)\n",
    "output_df[\"COMPLEX WORD COUNT\"]=output_df[\"processed_article_text\"].apply(number_of_complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3665f07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>processed_article_text</th>\n",
       "      <th>clean_words</th>\n",
       "      <th>personal_pronouns_text</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes -...</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes  ...</td>\n",
       "      <td>[AI, healthcare, Improve, Patient, Outcomes, B...</td>\n",
       "      <td>[us]</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>5.556962</td>\n",
       "      <td>2.275449</td>\n",
       "      <td>[Blackcoffer, Introduction, anything, infectio...</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.100552</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>[What, Creation, Taking, Over, Creator, Blackc...</td>\n",
       "      <td>[we, us, us, us, we, we]</td>\n",
       "      <td>809</td>\n",
       "      <td>6</td>\n",
       "      <td>4.718232</td>\n",
       "      <td>1.946309</td>\n",
       "      <td>[Blackcoffer, fascination, potential, tinkerin...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>[What, Jobs, Will, Robots, Take, From, Humans,...</td>\n",
       "      <td>[us, us]</td>\n",
       "      <td>1051</td>\n",
       "      <td>2</td>\n",
       "      <td>5.351841</td>\n",
       "      <td>2.200546</td>\n",
       "      <td>[Blackcoffer, Introduction, rapidly, evolving,...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.079415</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>[Will, Machine, Replace, The, Human, Future, W...</td>\n",
       "      <td>[us, we, us, we, we, we, we, we, we, we, we, w...</td>\n",
       "      <td>943</td>\n",
       "      <td>17</td>\n",
       "      <td>4.780822</td>\n",
       "      <td>1.952456</td>\n",
       "      <td>[Blackcoffer, Anything, intelligence, Artifici...</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Will AI Replace Us or Work With Us? - Blackcof...</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>Will AI Replace Us or Work With Us    Blackcof...</td>\n",
       "      <td>[Will, AI, Replace, Us, Work, With, Us, Blackc...</td>\n",
       "      <td>[us, we, we, we, we, us, us, we, we, us, us, us]</td>\n",
       "      <td>1034</td>\n",
       "      <td>12</td>\n",
       "      <td>4.936999</td>\n",
       "      <td>2.007742</td>\n",
       "      <td>[Blackcoffer, intelligence, invention, humanit...</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "\n",
       "                                                text  POSITIVE SCORE  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes -...              63   \n",
       "1  What if the Creation is Taking Over the Creato...              55   \n",
       "2  What Jobs Will Robots Take From Humans in The ...              65   \n",
       "3  Will Machine Replace The Human in the Future o...              55   \n",
       "4  Will AI Replace Us or Work With Us? - Blackcof...              48   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0              31        0.340426            0.072812   \n",
       "1              36        0.208791            0.100552   \n",
       "2              34        0.313131            0.084615   \n",
       "3              21        0.447368            0.079415   \n",
       "4              22        0.371429            0.060606   \n",
       "\n",
       "                              processed_article_text  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes  ...   \n",
       "1  What if the Creation is Taking Over the Creato...   \n",
       "2  What Jobs Will Robots Take From Humans in The ...   \n",
       "3  Will Machine Replace The Human in the Future o...   \n",
       "4  Will AI Replace Us or Work With Us    Blackcof...   \n",
       "\n",
       "                                         clean_words  \\\n",
       "0  [AI, healthcare, Improve, Patient, Outcomes, B...   \n",
       "1  [What, Creation, Taking, Over, Creator, Blackc...   \n",
       "2  [What, Jobs, Will, Robots, Take, From, Humans,...   \n",
       "3  [Will, Machine, Replace, The, Human, Future, W...   \n",
       "4  [Will, AI, Replace, Us, Work, With, Us, Blackc...   \n",
       "\n",
       "                              personal_pronouns_text  WORD COUNT  \\\n",
       "0                                               [us]        1203   \n",
       "1                           [we, us, us, us, we, we]         809   \n",
       "2                                           [us, us]        1051   \n",
       "3  [us, we, us, we, we, we, we, we, we, we, we, w...         943   \n",
       "4   [us, we, we, we, we, us, us, we, we, us, us, us]        1034   \n",
       "\n",
       "   PERSONAL PRONOUNS  AVG WORD LENGTH  SYLLABLE PER WORD  \\\n",
       "0                  1         5.556962           2.275449   \n",
       "1                  6         4.718232           1.946309   \n",
       "2                  2         5.351841           2.200546   \n",
       "3                 17         4.780822           1.952456   \n",
       "4                 12         4.936999           2.007742   \n",
       "\n",
       "                                       complex_words  COMPLEX WORD COUNT  \n",
       "0  [Blackcoffer, Introduction, anything, infectio...                 413  \n",
       "1  [Blackcoffer, fascination, potential, tinkerin...                 196  \n",
       "2  [Blackcoffer, Introduction, rapidly, evolving,...                 365  \n",
       "3  [Blackcoffer, Anything, intelligence, Artifici...                 243  \n",
       "4  [Blackcoffer, intelligence, invention, humanit...                 295  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845f4ac",
   "metadata": {},
   "source": [
    "#### Calculating the Average Sentence Length , Percentage of Complex Words , FOG index and adding them to the output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e7e9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def avg_sent_length(article_text):\n",
    "    average_sent_length=len(word_tokenize(article_text))/len(nltk.sent_tokenize(article_text))\n",
    "    return average_sent_length\n",
    "def prcnt_complex_words(article_text):\n",
    "    percentage_complex_words=number_of_complex_words(article_text)/len(word_tokenize(article_text))\n",
    "    return percentage_complex_words\n",
    "\n",
    "def fog(article_text):\n",
    "    Fog_index = 0.4 * (avg_sent_length(article_text) + prcnt_complex_words(article_text))\n",
    "    return Fog_index\n",
    "output_df[\"AVG SENTENCE LENGTH\"]=output_df[\"text\"].apply(avg_sent_length)\n",
    "output_df[\"PERCENTAGE OF COMPLEX WORDS\"]=output_df[\"text\"].apply(prcnt_complex_words)\n",
    "output_df[\"FOG INDEX\"]=output_df[\"text\"].apply(fog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e7b22e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>processed_article_text</th>\n",
       "      <th>clean_words</th>\n",
       "      <th>personal_pronouns_text</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes -...</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes  ...</td>\n",
       "      <td>[AI, healthcare, Improve, Patient, Outcomes, B...</td>\n",
       "      <td>[us]</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>5.556962</td>\n",
       "      <td>2.275449</td>\n",
       "      <td>[Blackcoffer, Introduction, anything, infectio...</td>\n",
       "      <td>413</td>\n",
       "      <td>38.711538</td>\n",
       "      <td>0.217586</td>\n",
       "      <td>15.571650</td>\n",
       "      <td>38.711538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.100552</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>[What, Creation, Taking, Over, Creator, Blackc...</td>\n",
       "      <td>[we, us, us, us, we, we]</td>\n",
       "      <td>809</td>\n",
       "      <td>6</td>\n",
       "      <td>4.718232</td>\n",
       "      <td>1.946309</td>\n",
       "      <td>[Blackcoffer, fascination, potential, tinkerin...</td>\n",
       "      <td>196</td>\n",
       "      <td>23.956522</td>\n",
       "      <td>0.131881</td>\n",
       "      <td>9.635361</td>\n",
       "      <td>23.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>[What, Jobs, Will, Robots, Take, From, Humans,...</td>\n",
       "      <td>[us, us]</td>\n",
       "      <td>1051</td>\n",
       "      <td>2</td>\n",
       "      <td>5.351841</td>\n",
       "      <td>2.200546</td>\n",
       "      <td>[Blackcoffer, Introduction, rapidly, evolving,...</td>\n",
       "      <td>365</td>\n",
       "      <td>29.106061</td>\n",
       "      <td>0.201458</td>\n",
       "      <td>11.723007</td>\n",
       "      <td>29.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.079415</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>[Will, Machine, Replace, The, Human, Future, W...</td>\n",
       "      <td>[us, we, us, we, we, we, we, we, we, we, we, w...</td>\n",
       "      <td>943</td>\n",
       "      <td>17</td>\n",
       "      <td>4.780822</td>\n",
       "      <td>1.952456</td>\n",
       "      <td>[Blackcoffer, Anything, intelligence, Artifici...</td>\n",
       "      <td>243</td>\n",
       "      <td>23.592105</td>\n",
       "      <td>0.139989</td>\n",
       "      <td>9.492838</td>\n",
       "      <td>23.592105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Will AI Replace Us or Work With Us? - Blackcof...</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>Will AI Replace Us or Work With Us    Blackcof...</td>\n",
       "      <td>[Will, AI, Replace, Us, Work, With, Us, Blackc...</td>\n",
       "      <td>[us, we, we, we, we, us, us, we, we, us, us, us]</td>\n",
       "      <td>1034</td>\n",
       "      <td>12</td>\n",
       "      <td>4.936999</td>\n",
       "      <td>2.007742</td>\n",
       "      <td>[Blackcoffer, intelligence, invention, humanit...</td>\n",
       "      <td>295</td>\n",
       "      <td>29.194030</td>\n",
       "      <td>0.158487</td>\n",
       "      <td>11.741007</td>\n",
       "      <td>29.194030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "\n",
       "                                                text  POSITIVE SCORE  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes -...              63   \n",
       "1  What if the Creation is Taking Over the Creato...              55   \n",
       "2  What Jobs Will Robots Take From Humans in The ...              65   \n",
       "3  Will Machine Replace The Human in the Future o...              55   \n",
       "4  Will AI Replace Us or Work With Us? - Blackcof...              48   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0              31        0.340426            0.072812   \n",
       "1              36        0.208791            0.100552   \n",
       "2              34        0.313131            0.084615   \n",
       "3              21        0.447368            0.079415   \n",
       "4              22        0.371429            0.060606   \n",
       "\n",
       "                              processed_article_text  \\\n",
       "0  AI in healthcare to Improve Patient Outcomes  ...   \n",
       "1  What if the Creation is Taking Over the Creato...   \n",
       "2  What Jobs Will Robots Take From Humans in The ...   \n",
       "3  Will Machine Replace The Human in the Future o...   \n",
       "4  Will AI Replace Us or Work With Us    Blackcof...   \n",
       "\n",
       "                                         clean_words  \\\n",
       "0  [AI, healthcare, Improve, Patient, Outcomes, B...   \n",
       "1  [What, Creation, Taking, Over, Creator, Blackc...   \n",
       "2  [What, Jobs, Will, Robots, Take, From, Humans,...   \n",
       "3  [Will, Machine, Replace, The, Human, Future, W...   \n",
       "4  [Will, AI, Replace, Us, Work, With, Us, Blackc...   \n",
       "\n",
       "                              personal_pronouns_text  WORD COUNT  \\\n",
       "0                                               [us]        1203   \n",
       "1                           [we, us, us, us, we, we]         809   \n",
       "2                                           [us, us]        1051   \n",
       "3  [us, we, us, we, we, we, we, we, we, we, we, w...         943   \n",
       "4   [us, we, we, we, we, us, us, we, we, us, us, us]        1034   \n",
       "\n",
       "   PERSONAL PRONOUNS  AVG WORD LENGTH  SYLLABLE PER WORD  \\\n",
       "0                  1         5.556962           2.275449   \n",
       "1                  6         4.718232           1.946309   \n",
       "2                  2         5.351841           2.200546   \n",
       "3                 17         4.780822           1.952456   \n",
       "4                 12         4.936999           2.007742   \n",
       "\n",
       "                                       complex_words  COMPLEX WORD COUNT  \\\n",
       "0  [Blackcoffer, Introduction, anything, infectio...                 413   \n",
       "1  [Blackcoffer, fascination, potential, tinkerin...                 196   \n",
       "2  [Blackcoffer, Introduction, rapidly, evolving,...                 365   \n",
       "3  [Blackcoffer, Anything, intelligence, Artifici...                 243   \n",
       "4  [Blackcoffer, intelligence, invention, humanit...                 295   \n",
       "\n",
       "   AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            38.711538                     0.217586  15.571650   \n",
       "1            23.956522                     0.131881   9.635361   \n",
       "2            29.106061                     0.201458  11.723007   \n",
       "3            23.592105                     0.139989   9.492838   \n",
       "4            29.194030                     0.158487  11.741007   \n",
       "\n",
       "   AVG NUMBER OF WORDS PER SENTENCE  \n",
       "0                         38.711538  \n",
       "1                         23.956522  \n",
       "2                         29.106061  \n",
       "3                         23.592105  \n",
       "4                         29.194030  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df[\"AVG NUMBER OF WORDS PER SENTENCE\"]=output_df[\"AVG SENTENCE LENGTH\"].copy()\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd57466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_required_columns=[\"URL_ID\",\"URL\",\"POSITIVE SCORE\",\"NEGATIVE SCORE\",\"POLARITY SCORE\",\"SUBJECTIVITY SCORE\",\"AVG SENTENCE LENGTH\",\"PERCENTAGE OF COMPLEX WORDS\",\"FOG INDEX\",\"AVG NUMBER OF WORDS PER SENTENCE\",\"COMPLEX WORD COUNT\",\"WORD COUNT\",\"SYLLABLE PER WORD\",\"PERSONAL PRONOUNS\",\"AVG WORD LENGTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23b79b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = output_df[list_of_required_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e6634",
   "metadata": {},
   "source": [
    "#### As there was no clear explanation about AVG SENTENCE LENGTH and AVG NUMBER OF WORDS PER SENTENCE in the text analysis document and they seemed to be same so calculated them by using the same formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a260823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>38.711538</td>\n",
       "      <td>0.217586</td>\n",
       "      <td>15.571650</td>\n",
       "      <td>38.711538</td>\n",
       "      <td>413</td>\n",
       "      <td>1203</td>\n",
       "      <td>2.275449</td>\n",
       "      <td>1</td>\n",
       "      <td>5.556962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.100552</td>\n",
       "      <td>23.956522</td>\n",
       "      <td>0.131881</td>\n",
       "      <td>9.635361</td>\n",
       "      <td>23.956522</td>\n",
       "      <td>196</td>\n",
       "      <td>809</td>\n",
       "      <td>1.946309</td>\n",
       "      <td>6</td>\n",
       "      <td>4.718232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>29.106061</td>\n",
       "      <td>0.201458</td>\n",
       "      <td>11.723007</td>\n",
       "      <td>29.106061</td>\n",
       "      <td>365</td>\n",
       "      <td>1051</td>\n",
       "      <td>2.200546</td>\n",
       "      <td>2</td>\n",
       "      <td>5.351841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.079415</td>\n",
       "      <td>23.592105</td>\n",
       "      <td>0.139989</td>\n",
       "      <td>9.492838</td>\n",
       "      <td>23.592105</td>\n",
       "      <td>243</td>\n",
       "      <td>943</td>\n",
       "      <td>1.952456</td>\n",
       "      <td>17</td>\n",
       "      <td>4.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>29.194030</td>\n",
       "      <td>0.158487</td>\n",
       "      <td>11.741007</td>\n",
       "      <td>29.194030</td>\n",
       "      <td>295</td>\n",
       "      <td>1034</td>\n",
       "      <td>2.007742</td>\n",
       "      <td>12</td>\n",
       "      <td>4.936999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              63   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              55   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              65   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              55   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              48   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              31        0.340426            0.072812            38.711538   \n",
       "1              36        0.208791            0.100552            23.956522   \n",
       "2              34        0.313131            0.084615            29.106061   \n",
       "3              21        0.447368            0.079415            23.592105   \n",
       "4              22        0.371429            0.060606            29.194030   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                     0.217586  15.571650                         38.711538   \n",
       "1                     0.131881   9.635361                         23.956522   \n",
       "2                     0.201458  11.723007                         29.106061   \n",
       "3                     0.139989   9.492838                         23.592105   \n",
       "4                     0.158487  11.741007                         29.194030   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 413        1203           2.275449                  1   \n",
       "1                 196         809           1.946309                  6   \n",
       "2                 365        1051           2.200546                  2   \n",
       "3                 243         943           1.952456                 17   \n",
       "4                 295        1034           2.007742                 12   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         5.556962  \n",
       "1         4.718232  \n",
       "2         5.351841  \n",
       "3         4.780822  \n",
       "4         4.936999  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afdd2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376398b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
